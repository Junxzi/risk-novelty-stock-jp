{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0531ad7-abdb-470c-ac41-7b4b5a79ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.abspath(\"..\"))\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2176c27-4c53-4726-bb2e-ab5f2b40499c",
   "metadata": {},
   "source": [
    "# EDINET APIで有価証券報告書を取得 → DB登録フロー\n",
    "\n",
    "以下のノートブックでは、\n",
    "1. 書類一覧 APIで提出書類一覧を取得  \n",
    "2. 書類取得 APIでCSV/XBRL等をダウンロード  \n",
    "3. ダウンロードしたファイルを展開し、パスを記録  \n",
    "4. PostgreSQLへレコードを登録  \n",
    "\n",
    "の一連を実装します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08bea9a-1fef-49ab-a2d9-d3eb7a3181a7",
   "metadata": {},
   "source": [
    "# Cell 1: ライブラリのインポート＆定数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656d8a91-fa71-4387-9dd9-cabadcf3471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: ライブラリのインポートと設定\n",
    "import os\n",
    "import zipfile\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "from db.connection import get_connection  # あなたの connection.py を指すように\n",
    "\n",
    "# ロギング設定\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')\n",
    "\n",
    "# EDINET API のベース URL とキー\n",
    "API_KEY = os.getenv(\"EDINET_API_KEY\")\n",
    "BASE_URL = \"https://api.edinet-fsa.go.jp/api/v2\"\n",
    "SAVE_ROOT = Path(\"data/raw/edinet\")  # ZIP/CSV を展開するルート\n",
    "\n",
    "# 取得対象の書類タイプ（2:年次, 3:半期, 4:四半期）\n",
    "DOC_TYPES = [\"120\", \"130\", \"140\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10e5555-8ad5-4961-9918-5db9575e4755",
   "metadata": {},
   "source": [
    "# Cell 2: EDINET API 呼び出し関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a3c01f-3a96-42f9-80f0-c205df661721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: 日付指定でメタデータを取得する関数\n",
    "def fetch_document_list_for_date(date: str, doc_type: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    date (YYYY-MM-DD) + doc_type (文字列) で EDINET の documents.json を呼び、\n",
    "    'results' 部分を DataFrame で返す。見つからなければ空 DF。\n",
    "    \"\"\"\n",
    "    params = {\"date\": date, \"type\": doc_type, \"resultType\": 1}\n",
    "    headers = {\"X-EDINET-APIKEY\": API_KEY}\n",
    "    r = requests.get(f\"{BASE_URL}/documents.json\", params=params, headers=headers)\n",
    "    if r.status_code == 200:\n",
    "        js = r.json()\n",
    "        return pd.DataFrame(js.get(\"results\", []))\n",
    "    elif r.status_code == 204:\n",
    "        # No Content\n",
    "        return pd.DataFrame()\n",
    "    else:\n",
    "        r.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d527187-5bc0-45b5-bfb6-2d1aa78c396e",
   "metadata": {},
   "source": [
    "# Cell 3: データベース登録用ユーティリティ＆テーブル読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3afddfa8-d771-4e99-8224-79647fafcd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching EDINET: 100%|██████████████████████████████████████████████| 3287/3287 [18:52<00:00,  2.90it/s]\n",
      "2025-07-01 17:21:15,445 [INFO] ▶︎ 取得メタデータ日数: 0 chunks\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: 期間（日付）をループしてメタデータを収集\n",
    "start = \"2017-01-01\"\n",
    "end   = \"2025-12-31\"\n",
    "\n",
    "all_docs = []\n",
    "dates = pd.date_range(start, end, freq=\"D\").astype(str)\n",
    "for date in tqdm(dates, desc=\"Fetching EDINET\"):\n",
    "    for t in DOC_TYPES:\n",
    "        df = fetch_document_list_for_date(date, t)\n",
    "        if not df.empty:\n",
    "            df[\"doc_type\"] = t\n",
    "            all_docs.append(df)\n",
    "\n",
    "# マージ前の合計\n",
    "logging.info(f\"▶︎ 取得メタデータ日数: {len(all_docs)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5640f9ef-c38f-432d-abad-c0ee4e4febd3",
   "metadata": {},
   "source": [
    "# Cell 4: 年次＋四半期レポートを日次ループでまとめて取得→登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f95744-0dcd-406e-9443-0861920c3578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching EDINET: 100%|██████████████████████████████████████████████| 3287/3287 [05:53<00:00,  9.29it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         all_docs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 結合して年単位で登録\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m df_all \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m▶︎ トータル取得件数: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_all)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 件\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m yr \u001b[38;5;129;01min\u001b[39;00m df_all[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmitDate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr[:\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n",
      "File \u001b[0;32m~/dev/risk-novelty-stock-jp/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/dev/risk-novelty-stock-jp/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/dev/risk-novelty-stock-jp/.venv/lib/python3.10/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Cell 4: 取得結果をまとめて重複除去\n",
    "if not all_docs:\n",
    "    raise RuntimeError(\"EDINET メタデータが一件も取得できませんでした。\")\n",
    "df_all = pd.concat(all_docs, ignore_index=True)\n",
    "logging.info(f\"▶︎ マージ後の総件数: {len(df_all):,}\")\n",
    "\n",
    "# docID で重複を除く\n",
    "df_all = df_all.drop_duplicates(subset=\"docID\")\n",
    "logging.info(f\"▶︎ docID 一意化後件数: {len(df_all):,}\")\n",
    "df_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adea7bf-2363-4496-b212-6c71bb299213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: companies マスタと突合、CSV をダウンロードして edinet_filings に登録\n",
    "def download_csv_and_unpack(doc_id: str, save_dir: Path) -> Path:\n",
    "    \"\"\"ZIP 取得 → 解凍 → 最初の CSV ファイルパスを返却\"\"\"\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    zippath = save_dir / f\"{doc_id}.zip\"\n",
    "    r = requests.get(f\"{BASE_URL}/documents/{doc_id}\", params={\"type\":5}, headers={\"X-EDINET-APIKEY\":API_KEY}, stream=True)\n",
    "    r.raise_for_status()\n",
    "    with open(zippath, \"wb\") as f:\n",
    "        for chunk in r.iter_content(1024):\n",
    "            f.write(chunk)\n",
    "    with zipfile.ZipFile(zippath) as z:\n",
    "        members = [n for n in z.namelist() if n.lower().endswith(\".csv\")]\n",
    "        z.extractall(save_dir, members)\n",
    "        return save_dir / members[0]\n",
    "\n",
    "# DB 接続して companies を読込\n",
    "conn = get_connection()\n",
    "cur  = conn.cursor()\n",
    "df_comp = pd.read_sql(\"SELECT company_id, edinet_code FROM companies\", conn)\n",
    "\n",
    "records = []\n",
    "for _, row in tqdm(df_all.iterrows(), total=len(df_all), desc=\"Download & Prepare\"):\n",
    "    doc_id = row[\"docID\"]\n",
    "    edc    = row[\"edinetCode\"]\n",
    "    # マスタにある企業のみ処理\n",
    "    match = df_comp[df_comp[\"edinet_code\"] == edc]\n",
    "    if match.empty:\n",
    "        continue\n",
    "    cid = match[\"company_id\"].iloc[0]\n",
    "    try:\n",
    "        csv_path = download_csv_and_unpack(doc_id, SAVE_ROOT / row[\"submitDate\"][:4] / edc)\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"ZIP 展開失敗: {doc_id} / {e}\")\n",
    "        continue\n",
    "    records.append((\n",
    "        cid,\n",
    "        edc,\n",
    "        doc_id,\n",
    "        row[\"docTypeCode\"],      # メタデータ中の書類コード\n",
    "        row[\"submitDate\"],\n",
    "        row[\"docDescription\"],\n",
    "        str(csv_path)\n",
    "    ))\n",
    "\n",
    "# INSERT\n",
    "execute_values(cur, \"\"\"\n",
    "    INSERT INTO edinet_filings\n",
    "      (company_id, edinet_code, doc_id, doc_type_code, submit_date, description, csv_path)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (company_id, doc_id) DO NOTHING;\n",
    "\"\"\", records)\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "logging.info(f\"✅ 登録完了: {len(records):,} 件\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sotsuken (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
