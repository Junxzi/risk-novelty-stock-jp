{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "808e34ae",
   "metadata": {},
   "source": [
    "## ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚§ãƒƒãƒã¨è§£å‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719bb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.abspath(\"..\"))\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6526bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import pandas as pd\n",
    "from scripts.data_fetcher import unzip_file\n",
    "\n",
    "unzip_file(\"data/raw/Edinetcode_20250625.zip\", \"data/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e548da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")  # src/ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã«1éšå±¤ä¸Šã¸\n",
    "\n",
    "from scripts.data_fetcher import fetch_and_save_snapshots\n",
    "\n",
    "# å®Ÿè¡Œï¼ˆ2017ã€œ2024å¹´åˆ†ã‚’ä¿å­˜ï¼‰\n",
    "fetch_and_save_snapshots(start_year=2017, end_year=2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1555ce71",
   "metadata": {},
   "source": [
    "## èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b05b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_topix_2017 = pd.read_csv(\"data/raw/topix_growth_snapshots/2017_topix_growth.csv\")\n",
    "df_edinet = pd.read_csv(\"data/raw/EdinetcodeDlInfo.csv\", encoding=\"cp932\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topix_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b600bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edinet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f9d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edinet[\"è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰\"] = pd.to_numeric(\n",
    "    df_edinet[\"è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰\"], errors=\"coerce\"\n",
    ").astype(\"Int64\")\n",
    "df_merged2017 = pd.merge(\n",
    "    df_topix_2017, df_edinet, left_on=\"Code\", right_on=\"è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1188f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_unmatched = df_merged2017[df_merged2017[\"è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰\"].isna()]\n",
    "matches = []\n",
    "\n",
    "# 1è¡Œãšã¤éŠ˜æŸ„åã‚’å«ã‚€æå‡ºè€…åã‚’æ¢ã™\n",
    "for i, row in _df_unmatched.iterrows():\n",
    "    name = row[\"CompanyName\"]\n",
    "    hit = df_edinet[df_edinet[\"æå‡ºè€…å\"].str.contains(name, na=False)]\n",
    "    if not hit.empty:\n",
    "        # æœ€åˆã«ãƒãƒƒãƒã—ãŸã‚‚ã®ã ã‘ä½¿ã†ï¼ˆè¤‡æ•°ãƒãƒƒãƒå¯¾å¿œã‚‚å¯èƒ½ï¼‰\n",
    "        merged_row = row.to_dict()\n",
    "        merged_row.update(hit.iloc[0].to_dict())\n",
    "        matches.append(merged_row)\n",
    "\n",
    "# DataFrameåŒ–\n",
    "matched_df = pd.DataFrame(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged2017[df_merged2017[\"Code\"] == 26510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4378f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ä¸¡æ–¹ã«å…±é€šã™ã‚‹è£œå®Œå¯¾è±¡ã‚«ãƒ©ãƒ ã‚’å–å¾—\n",
    "cols_to_update = list(set(matched_df.columns) & set(df_merged2017.columns))\n",
    "\n",
    "# 2. CompanyNameã‚’ã‚­ãƒ¼ã«ã—ã¦ãƒ«ãƒ¼ãƒ—ã§è£œå®Œ\n",
    "for _, row in matched_df.iterrows():\n",
    "    company_name = row[\"CompanyName\"]\n",
    "    for col in cols_to_update:\n",
    "        # df_merged2017ã®è©²å½“è¡Œã«å¯¾ã—ã¦ã€æ¬ æã—ã¦ã„ã‚‹ç®‡æ‰€ã ã‘è£œå®Œ\n",
    "        mask = (df_merged2017[\"CompanyName\"] == company_name) & (\n",
    "            df_merged2017[col].isna()\n",
    "        )\n",
    "        df_merged2017.loc[mask, col] = row[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0290173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import pandas as pd\n",
    "\n",
    "df_merged2017 = pd.read_csv(\"data/processed/topix_companies_2017.csv\")\n",
    "\n",
    "# ã‚«ãƒ©ãƒ åã‚’çµ±ä¸€\n",
    "df_merged2017 = df_merged2017.rename(\n",
    "    columns={\n",
    "        \"æå‡ºè€…å\": \"name_ja\",\n",
    "        \"æå‡ºè€…æ³•äººç•ªå·\": \"corp_number\",\n",
    "        \"ï¼¥ï¼¤ï¼©ï¼®ï¼¥ï¼´ã‚³ãƒ¼ãƒ‰\": \"edinet_code\",\n",
    "        \"Code\": \"security_code\",  # J-Quantsã§å¾—ã‚‰ã‚Œã‚‹ \"Code\" åˆ—ï¼ˆè¨¼åˆ¸ã‚³ãƒ¼ãƒ‰ï¼‰\n",
    "        \"æå‡ºè€…æ¥­ç¨®\": \"sector_33\",\n",
    "        \"Sector17CodeName\": \"sector_17\",\n",
    "        \"ScaleCategory\": \"scale_category\",\n",
    "        \"MarketCode\": \"market_code\",\n",
    "        \"æå‡ºè€…åï¼ˆè‹±å­—ï¼‰\": \"name_en\",\n",
    "        \"æ‰€åœ¨åœ°\": \"address\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782da35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged2017.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdfe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged2017.to_csv(\"data/processed/topix_companies_2017.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c186e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "from psycopg2.extras import execute_values\n",
    "from db.connection import get_connection\n",
    "from scripts.preprocess import overwrite_company_ids_if_exists\n",
    "\n",
    "# ----------- â‘  å¹´åº¦æŒ‡å®š & ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ ----------\n",
    "YEAR = 2017\n",
    "CSV_PATH = f\"data/processed/topix_companies_{YEAR}.csv\"\n",
    "\n",
    "# ----------- â‘¡ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & ã‚«ãƒ©ãƒ çµ±ä¸€ ----------\n",
    "df = pd.read_csv(CSV_PATH, dtype=str).fillna(\"\")\n",
    "\n",
    "column_map = {\n",
    "    \"æå‡ºè€…å\": \"name_ja\",\n",
    "    \"æå‡ºè€…æ³•äººç•ªå·\": \"corp_number\",\n",
    "    \"ï¼¥ï¼¤ï¼©ï¼®ï¼¥ï¼´ã‚³ãƒ¼ãƒ‰\": \"edinet_code\",\n",
    "    \"Code\": \"security_code\",\n",
    "    \"æå‡ºè€…æ¥­ç¨®\": \"sector_33\",\n",
    "    \"Sector17CodeName\": \"sector_17\",\n",
    "    \"ScaleCategory\": \"scale_category\",\n",
    "    \"MarketCode\": \"market_code\",\n",
    "    \"æå‡ºè€…åï¼ˆè‹±å­—ï¼‰\": \"name_en\",\n",
    "    \"æ‰€åœ¨åœ°\": \"address\",\n",
    "}\n",
    "df = df.rename(columns=column_map)\n",
    "\n",
    "keep_cols = [\n",
    "    \"security_code\",\n",
    "    \"name_ja\",\n",
    "    \"name_en\",\n",
    "    \"sector_17\",\n",
    "    \"sector_33\",\n",
    "    \"scale_category\",\n",
    "    \"market_code\",\n",
    "    \"edinet_code\",\n",
    "    \"address\",\n",
    "    \"corp_number\",\n",
    "]\n",
    "df = df[keep_cols]\n",
    "\n",
    "# æ•´å½¢å‡¦ç†\n",
    "df[\"security_code\"] = df[\"security_code\"].str.zfill(5)\n",
    "df[\"edinet_code\"] = df[\"edinet_code\"].str.zfill(6)\n",
    "df[\"corp_number\"] = df[\"corp_number\"].apply(\n",
    "    lambda x: str(int(float(x))).zfill(13) if pd.notnull(x) and x != \"\" else \"\"\n",
    ")\n",
    "\n",
    "# ----------- â‘¢ DBæ¥ç¶š & company_id ä¸Šæ›¸ã ----------\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "df = overwrite_company_ids_if_exists(df, cur)\n",
    "\n",
    "\n",
    "# ----------- â‘£ UUIDãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ & é‡è¤‡ãƒã‚§ãƒƒã‚¯ ----------\n",
    "def is_valid_uuid(val: str) -> bool:\n",
    "    try:\n",
    "        uuid.UUID(str(val))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "df[\"company_id\"] = df[\"company_id\"].astype(str)\n",
    "valid_mask = df[\"company_id\"].apply(is_valid_uuid)\n",
    "\n",
    "# ç„¡åŠ¹ãªUUIDæ¤œå‡º\n",
    "invalid_df = df[~valid_mask]\n",
    "if not invalid_df.empty:\n",
    "    print(\"ğŸŸ¥ ç„¡åŠ¹ãª company_id ã‚’æŒã¤ãƒ¬ã‚³ãƒ¼ãƒ‰:\")\n",
    "    display(invalid_df)\n",
    "\n",
    "# é‡è¤‡æ¤œå‡º\n",
    "duplicates = df[valid_mask].duplicated(subset=[\"company_id\"], keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"âš ï¸ company_id ãŒé‡è¤‡ã—ã¦ã„ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆåŒä¸€å¹´åº¦å†…ï¼‰:\")\n",
    "    display(df[valid_mask][duplicates])\n",
    "\n",
    "# æœ‰åŠ¹ãªUUIDã®ã¿æ®‹ã™\n",
    "df = df[valid_mask].copy()\n",
    "\n",
    "print(\"ğŸ” company_idãŒæœ‰åŠ¹ãªä»¶æ•°:\", len(df))\n",
    "print(\"âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯ãª company_id ä»¶æ•°:\", df[\"company_id\"].nunique())\n",
    "\n",
    "# ----------- â‘¤ companies ãƒ†ãƒ¼ãƒ–ãƒ«ã«å…ˆã«æŒ¿å…¥ï¼ˆå¤–éƒ¨ã‚­ãƒ¼ç”¨ï¼‰ ----------\n",
    "company_records = [\n",
    "    (row[\"company_id\"], row[\"corp_number\"], row[\"edinet_code\"], row[\"security_code\"])\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO companies (company_id, corp_number, edinet_code, security_code)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (company_id) DO UPDATE\n",
    "    SET corp_number = EXCLUDED.corp_number,\n",
    "        edinet_code = EXCLUDED.edinet_code,\n",
    "        security_code = EXCLUDED.security_code;\n",
    "\"\"\",\n",
    "    company_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¥ company_profiles ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥ or æ›´æ–° ----------\n",
    "profile_records = [\n",
    "    (\n",
    "        row[\"company_id\"],\n",
    "        YEAR,\n",
    "        row[\"name_ja\"],\n",
    "        row[\"name_en\"],\n",
    "        row[\"sector_17\"],\n",
    "        row[\"sector_33\"],\n",
    "        row[\"scale_category\"],\n",
    "        row[\"market_code\"].zfill(3),\n",
    "        row[\"address\"],\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO company_profiles (\n",
    "        company_id, year, name_ja, name_en,\n",
    "        sector_17, sector_33, scale_category, market_code, address\n",
    "    ) VALUES %s\n",
    "    ON CONFLICT (company_id, year) DO UPDATE\n",
    "    SET name_ja = EXCLUDED.name_ja,\n",
    "        name_en = EXCLUDED.name_en,\n",
    "        sector_17 = EXCLUDED.sector_17,\n",
    "        sector_33 = EXCLUDED.sector_33,\n",
    "        scale_category = EXCLUDED.scale_category,\n",
    "        market_code = EXCLUDED.market_code,\n",
    "        address = EXCLUDED.address;\n",
    "\"\"\",\n",
    "    profile_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¦ ã‚³ãƒŸãƒƒãƒˆ & çµ‚äº†å‡¦ç† ----------\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"âœ… {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {YEAR} å¹´åˆ†ã¨ã—ã¦æŒ¿å…¥ãƒ»æ›´æ–°ã—ã¾ã—ãŸã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cee7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2018\n",
    "from scripts.preprocess import load_topix_and_edinet\n",
    "\n",
    "df_2018 = load_topix_and_edinet(\n",
    "    \"data/raw/topix_growth_snapshots/2018_topix_growth.csv\",\n",
    "    \"data/raw/EdinetcodeDlInfo.csv\",\n",
    ")\n",
    "df_2018.to_csv(\"data/processed/topix_companies_2018.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2d3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ã“ã“ã§æ‰‹å‹•ã§è£œå®Œã‚’è¡Œã†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c700ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "from psycopg2.extras import execute_values\n",
    "from db.connection import get_connection\n",
    "from scripts.preprocess import overwrite_company_ids_if_exists\n",
    "\n",
    "# ----------- â‘  å¹´åº¦æŒ‡å®š & ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ ----------\n",
    "YEAR = 2018\n",
    "CSV_PATH = f\"data/processed/topix_companies_{YEAR}.csv\"\n",
    "\n",
    "# ----------- â‘¡ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & ã‚«ãƒ©ãƒ çµ±ä¸€ ----------\n",
    "df = pd.read_csv(CSV_PATH, dtype=str).fillna(\"\")\n",
    "\n",
    "column_map = {\n",
    "    \"æå‡ºè€…å\": \"name_ja\",\n",
    "    \"æå‡ºè€…æ³•äººç•ªå·\": \"corp_number\",\n",
    "    \"ï¼¥ï¼¤ï¼©ï¼®ï¼¥ï¼´ã‚³ãƒ¼ãƒ‰\": \"edinet_code\",\n",
    "    \"Code\": \"security_code\",\n",
    "    \"æå‡ºè€…æ¥­ç¨®\": \"sector_33\",\n",
    "    \"Sector17CodeName\": \"sector_17\",\n",
    "    \"ScaleCategory\": \"scale_category\",\n",
    "    \"MarketCode\": \"market_code\",\n",
    "    \"æå‡ºè€…åï¼ˆè‹±å­—ï¼‰\": \"name_en\",\n",
    "    \"æ‰€åœ¨åœ°\": \"address\",\n",
    "}\n",
    "df = df.rename(columns=column_map)\n",
    "\n",
    "keep_cols = [\n",
    "    \"security_code\",\n",
    "    \"name_ja\",\n",
    "    \"name_en\",\n",
    "    \"sector_17\",\n",
    "    \"sector_33\",\n",
    "    \"scale_category\",\n",
    "    \"market_code\",\n",
    "    \"edinet_code\",\n",
    "    \"address\",\n",
    "    \"corp_number\",\n",
    "]\n",
    "df = df[keep_cols]\n",
    "\n",
    "# æ•´å½¢å‡¦ç†\n",
    "df[\"security_code\"] = df[\"security_code\"].str.zfill(5)\n",
    "df[\"edinet_code\"] = df[\"edinet_code\"].str.zfill(6)\n",
    "df[\"corp_number\"] = df[\"corp_number\"].apply(\n",
    "    lambda x: str(int(float(x))).zfill(13) if pd.notnull(x) and x != \"\" else \"\"\n",
    ")\n",
    "\n",
    "# ----------- â‘¢ DBæ¥ç¶š & company_id ä¸Šæ›¸ã ----------\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "df = overwrite_company_ids_if_exists(df, cur)\n",
    "\n",
    "\n",
    "# ----------- â‘£ UUIDãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ & é‡è¤‡ãƒã‚§ãƒƒã‚¯ ----------\n",
    "def is_valid_uuid(val: str) -> bool:\n",
    "    try:\n",
    "        uuid.UUID(str(val))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "df[\"company_id\"] = df[\"company_id\"].astype(str)\n",
    "valid_mask = df[\"company_id\"].apply(is_valid_uuid)\n",
    "\n",
    "# ç„¡åŠ¹ãªUUIDæ¤œå‡º\n",
    "invalid_df = df[~valid_mask]\n",
    "if not invalid_df.empty:\n",
    "    print(\"ğŸŸ¥ ç„¡åŠ¹ãª company_id ã‚’æŒã¤ãƒ¬ã‚³ãƒ¼ãƒ‰:\")\n",
    "    display(invalid_df)\n",
    "\n",
    "# é‡è¤‡æ¤œå‡º\n",
    "duplicates = df[valid_mask].duplicated(subset=[\"company_id\"], keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"âš ï¸ company_id ãŒé‡è¤‡ã—ã¦ã„ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆåŒä¸€å¹´åº¦å†…ï¼‰:\")\n",
    "    display(df[valid_mask][duplicates])\n",
    "\n",
    "# æœ‰åŠ¹ãªUUIDã®ã¿æ®‹ã™\n",
    "df = df[valid_mask].copy()\n",
    "\n",
    "print(\"ğŸ” company_idãŒæœ‰åŠ¹ãªä»¶æ•°:\", len(df))\n",
    "print(\"âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯ãª company_id ä»¶æ•°:\", df[\"company_id\"].nunique())\n",
    "\n",
    "# ----------- â‘¤ companies ãƒ†ãƒ¼ãƒ–ãƒ«ã«å…ˆã«æŒ¿å…¥ï¼ˆå¤–éƒ¨ã‚­ãƒ¼ç”¨ï¼‰ ----------\n",
    "company_records = [\n",
    "    (row[\"company_id\"], row[\"corp_number\"], row[\"edinet_code\"], row[\"security_code\"])\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO companies (company_id, corp_number, edinet_code, security_code)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (company_id) DO UPDATE\n",
    "    SET corp_number = EXCLUDED.corp_number,\n",
    "        edinet_code = EXCLUDED.edinet_code,\n",
    "        security_code = EXCLUDED.security_code;\n",
    "\"\"\",\n",
    "    company_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¥ company_profiles ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥ or æ›´æ–° ----------\n",
    "profile_records = [\n",
    "    (\n",
    "        row[\"company_id\"],\n",
    "        YEAR,\n",
    "        row[\"name_ja\"],\n",
    "        row[\"name_en\"],\n",
    "        row[\"sector_17\"],\n",
    "        row[\"sector_33\"],\n",
    "        row[\"scale_category\"],\n",
    "        row[\"market_code\"].zfill(3),\n",
    "        row[\"address\"],\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO company_profiles (\n",
    "        company_id, year, name_ja, name_en,\n",
    "        sector_17, sector_33, scale_category, market_code, address\n",
    "    ) VALUES %s\n",
    "    ON CONFLICT (company_id, year) DO UPDATE\n",
    "    SET name_ja = EXCLUDED.name_ja,\n",
    "        name_en = EXCLUDED.name_en,\n",
    "        sector_17 = EXCLUDED.sector_17,\n",
    "        sector_33 = EXCLUDED.sector_33,\n",
    "        scale_category = EXCLUDED.scale_category,\n",
    "        market_code = EXCLUDED.market_code,\n",
    "        address = EXCLUDED.address;\n",
    "\"\"\",\n",
    "    profile_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¦ ã‚³ãƒŸãƒƒãƒˆ & çµ‚äº†å‡¦ç† ----------\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"âœ… {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {YEAR} å¹´åˆ†ã¨ã—ã¦æŒ¿å…¥ãƒ»æ›´æ–°ã—ã¾ã—ãŸã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d75b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2019å¹´\n",
    "from scripts.preprocess import load_topix_and_edinet\n",
    "\n",
    "df_2019 = load_topix_and_edinet(\n",
    "    \"data/raw/topix_growth_snapshots/2019_topix_growth.csv\",\n",
    "    \"data/raw/EdinetcodeDlInfo.csv\",\n",
    ")\n",
    "df_2019.to_csv(\"data/processed/topix_companies_2019.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53500780",
   "metadata": {},
   "outputs": [],
   "source": [
    "## æ‰‹å‹•ã§è£œå®Œã€LINE yahooã‚‚å‡¦ç†å¿…è¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca1471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "from psycopg2.extras import execute_values\n",
    "from db.connection import get_connection\n",
    "from scripts.preprocess import overwrite_company_ids_if_exists\n",
    "\n",
    "# ----------- â‘  å¹´åº¦æŒ‡å®š & ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ ----------\n",
    "YEAR = 2019\n",
    "CSV_PATH = f\"data/processed/topix_companies_{YEAR}.csv\"\n",
    "\n",
    "# ----------- â‘¡ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & ã‚«ãƒ©ãƒ çµ±ä¸€ ----------\n",
    "df = pd.read_csv(CSV_PATH, dtype=str).fillna(\"\")\n",
    "\n",
    "column_map = {\n",
    "    \"æå‡ºè€…å\": \"name_ja\",\n",
    "    \"æå‡ºè€…æ³•äººç•ªå·\": \"corp_number\",\n",
    "    \"ï¼¥ï¼¤ï¼©ï¼®ï¼¥ï¼´ã‚³ãƒ¼ãƒ‰\": \"edinet_code\",\n",
    "    \"Code\": \"security_code\",\n",
    "    \"æå‡ºè€…æ¥­ç¨®\": \"sector_33\",\n",
    "    \"Sector17CodeName\": \"sector_17\",\n",
    "    \"ScaleCategory\": \"scale_category\",\n",
    "    \"MarketCode\": \"market_code\",\n",
    "    \"æå‡ºè€…åï¼ˆè‹±å­—ï¼‰\": \"name_en\",\n",
    "    \"æ‰€åœ¨åœ°\": \"address\",\n",
    "}\n",
    "df = df.rename(columns=column_map)\n",
    "\n",
    "keep_cols = [\n",
    "    \"security_code\",\n",
    "    \"name_ja\",\n",
    "    \"name_en\",\n",
    "    \"sector_17\",\n",
    "    \"sector_33\",\n",
    "    \"scale_category\",\n",
    "    \"market_code\",\n",
    "    \"edinet_code\",\n",
    "    \"address\",\n",
    "    \"corp_number\",\n",
    "]\n",
    "df = df[keep_cols]\n",
    "\n",
    "# æ•´å½¢å‡¦ç†\n",
    "df[\"security_code\"] = df[\"security_code\"].str.zfill(5)\n",
    "df[\"edinet_code\"] = df[\"edinet_code\"].str.zfill(6)\n",
    "df[\"corp_number\"] = df[\"corp_number\"].apply(\n",
    "    lambda x: str(int(float(x))).zfill(13) if pd.notnull(x) and x != \"\" else \"\"\n",
    ")\n",
    "\n",
    "# ----------- â‘¢ DBæ¥ç¶š & company_id ä¸Šæ›¸ã ----------\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "df = overwrite_company_ids_if_exists(df, cur)\n",
    "\n",
    "\n",
    "# ----------- â‘£ UUIDãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ & é‡è¤‡ãƒã‚§ãƒƒã‚¯ ----------\n",
    "def is_valid_uuid(val: str) -> bool:\n",
    "    try:\n",
    "        uuid.UUID(str(val))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "df[\"company_id\"] = df[\"company_id\"].astype(str)\n",
    "valid_mask = df[\"company_id\"].apply(is_valid_uuid)\n",
    "\n",
    "# ç„¡åŠ¹ãªUUIDæ¤œå‡º\n",
    "invalid_df = df[~valid_mask]\n",
    "if not invalid_df.empty:\n",
    "    print(\"ğŸŸ¥ ç„¡åŠ¹ãª company_id ã‚’æŒã¤ãƒ¬ã‚³ãƒ¼ãƒ‰:\")\n",
    "    display(invalid_df)\n",
    "\n",
    "# é‡è¤‡æ¤œå‡º\n",
    "duplicates = df[valid_mask].duplicated(subset=[\"company_id\"], keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"âš ï¸ company_id ãŒé‡è¤‡ã—ã¦ã„ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆåŒä¸€å¹´åº¦å†…ï¼‰:\")\n",
    "    display(df[valid_mask][duplicates])\n",
    "\n",
    "# æœ‰åŠ¹ãªUUIDã®ã¿æ®‹ã™\n",
    "df = df[valid_mask].copy()\n",
    "\n",
    "print(\"ğŸ” company_idãŒæœ‰åŠ¹ãªä»¶æ•°:\", len(df))\n",
    "print(\"âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯ãª company_id ä»¶æ•°:\", df[\"company_id\"].nunique())\n",
    "\n",
    "# ----------- â‘¤ companies ãƒ†ãƒ¼ãƒ–ãƒ«ã«å…ˆã«æŒ¿å…¥ï¼ˆå¤–éƒ¨ã‚­ãƒ¼ç”¨ï¼‰ ----------\n",
    "company_records = [\n",
    "    (row[\"company_id\"], row[\"corp_number\"], row[\"edinet_code\"], row[\"security_code\"])\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO companies (company_id, corp_number, edinet_code, security_code)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (company_id) DO UPDATE\n",
    "    SET corp_number = EXCLUDED.corp_number,\n",
    "        edinet_code = EXCLUDED.edinet_code,\n",
    "        security_code = EXCLUDED.security_code;\n",
    "\"\"\",\n",
    "    company_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¥ company_profiles ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥ or æ›´æ–° ----------\n",
    "profile_records = [\n",
    "    (\n",
    "        row[\"company_id\"],\n",
    "        YEAR,\n",
    "        row[\"name_ja\"],\n",
    "        row[\"name_en\"],\n",
    "        row[\"sector_17\"],\n",
    "        row[\"sector_33\"],\n",
    "        row[\"scale_category\"],\n",
    "        row[\"market_code\"].zfill(3),\n",
    "        row[\"address\"],\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO company_profiles (\n",
    "        company_id, year, name_ja, name_en,\n",
    "        sector_17, sector_33, scale_category, market_code, address\n",
    "    ) VALUES %s\n",
    "    ON CONFLICT (company_id, year) DO UPDATE\n",
    "    SET name_ja = EXCLUDED.name_ja,\n",
    "        name_en = EXCLUDED.name_en,\n",
    "        sector_17 = EXCLUDED.sector_17,\n",
    "        sector_33 = EXCLUDED.sector_33,\n",
    "        scale_category = EXCLUDED.scale_category,\n",
    "        market_code = EXCLUDED.market_code,\n",
    "        address = EXCLUDED.address;\n",
    "\"\"\",\n",
    "    profile_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¦ ã‚³ãƒŸãƒƒãƒˆ & çµ‚äº†å‡¦ç† ----------\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"âœ… {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {YEAR} å¹´åˆ†ã¨ã—ã¦æŒ¿å…¥ãƒ»æ›´æ–°ã—ã¾ã—ãŸã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f49fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2020\n",
    "from scripts.preprocess import load_topix_and_edinet\n",
    "\n",
    "df_2020 = load_topix_and_edinet(\n",
    "    \"data/raw/topix_growth_snapshots/2020_topix_growth.csv\",\n",
    "    \"data/raw/EdinetcodeDlInfo.csv\",\n",
    ")\n",
    "df_2020.to_csv(\"data/processed/topix_companies_2020.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## æ‰‹å‹•ã§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "from psycopg2.extras import execute_values\n",
    "from db.connection import get_connection\n",
    "from scripts.preprocess import overwrite_company_ids_if_exists\n",
    "\n",
    "# ----------- â‘  å¹´åº¦æŒ‡å®š & ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ ----------\n",
    "YEAR = 2020\n",
    "CSV_PATH = f\"data/processed/topix_companies_{YEAR}.csv\"\n",
    "\n",
    "# ----------- â‘¡ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & ã‚«ãƒ©ãƒ çµ±ä¸€ ----------\n",
    "df = pd.read_csv(CSV_PATH, dtype=str).fillna(\"\")\n",
    "\n",
    "column_map = {\n",
    "    \"æå‡ºè€…å\": \"name_ja\",\n",
    "    \"æå‡ºè€…æ³•äººç•ªå·\": \"corp_number\",\n",
    "    \"ï¼¥ï¼¤ï¼©ï¼®ï¼¥ï¼´ã‚³ãƒ¼ãƒ‰\": \"edinet_code\",\n",
    "    \"Code\": \"security_code\",\n",
    "    \"æå‡ºè€…æ¥­ç¨®\": \"sector_33\",\n",
    "    \"Sector17CodeName\": \"sector_17\",\n",
    "    \"ScaleCategory\": \"scale_category\",\n",
    "    \"MarketCode\": \"market_code\",\n",
    "    \"æå‡ºè€…åï¼ˆè‹±å­—ï¼‰\": \"name_en\",\n",
    "    \"æ‰€åœ¨åœ°\": \"address\",\n",
    "}\n",
    "df = df.rename(columns=column_map)\n",
    "\n",
    "keep_cols = [\n",
    "    \"security_code\",\n",
    "    \"name_ja\",\n",
    "    \"name_en\",\n",
    "    \"sector_17\",\n",
    "    \"sector_33\",\n",
    "    \"scale_category\",\n",
    "    \"market_code\",\n",
    "    \"edinet_code\",\n",
    "    \"address\",\n",
    "    \"corp_number\",\n",
    "]\n",
    "df = df[keep_cols]\n",
    "\n",
    "# æ•´å½¢å‡¦ç†\n",
    "df[\"security_code\"] = df[\"security_code\"].str.zfill(5)\n",
    "df[\"edinet_code\"] = df[\"edinet_code\"].str.zfill(6)\n",
    "df[\"corp_number\"] = df[\"corp_number\"].apply(\n",
    "    lambda x: str(int(float(x))).zfill(13) if pd.notnull(x) and x != \"\" else \"\"\n",
    ")\n",
    "\n",
    "# ----------- â‘¢ DBæ¥ç¶š & company_id ä¸Šæ›¸ã ----------\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "df = overwrite_company_ids_if_exists(df, cur)\n",
    "\n",
    "\n",
    "# ----------- â‘£ UUIDãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ & é‡è¤‡ãƒã‚§ãƒƒã‚¯ ----------\n",
    "def is_valid_uuid(val: str) -> bool:\n",
    "    try:\n",
    "        uuid.UUID(str(val))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "df[\"company_id\"] = df[\"company_id\"].astype(str)\n",
    "valid_mask = df[\"company_id\"].apply(is_valid_uuid)\n",
    "\n",
    "# ç„¡åŠ¹ãªUUIDæ¤œå‡º\n",
    "invalid_df = df[~valid_mask]\n",
    "if not invalid_df.empty:\n",
    "    print(\"ğŸŸ¥ ç„¡åŠ¹ãª company_id ã‚’æŒã¤ãƒ¬ã‚³ãƒ¼ãƒ‰:\")\n",
    "    display(invalid_df)\n",
    "\n",
    "# é‡è¤‡æ¤œå‡º\n",
    "duplicates = df[valid_mask].duplicated(subset=[\"company_id\"], keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"âš ï¸ company_id ãŒé‡è¤‡ã—ã¦ã„ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆåŒä¸€å¹´åº¦å†…ï¼‰:\")\n",
    "    display(df[valid_mask][duplicates])\n",
    "\n",
    "# æœ‰åŠ¹ãªUUIDã®ã¿æ®‹ã™\n",
    "df = df[valid_mask].copy()\n",
    "\n",
    "print(\"ğŸ” company_idãŒæœ‰åŠ¹ãªä»¶æ•°:\", len(df))\n",
    "print(\"âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯ãª company_id ä»¶æ•°:\", df[\"company_id\"].nunique())\n",
    "\n",
    "# ----------- â‘¤ companies ãƒ†ãƒ¼ãƒ–ãƒ«ã«å…ˆã«æŒ¿å…¥ï¼ˆå¤–éƒ¨ã‚­ãƒ¼ç”¨ï¼‰ ----------\n",
    "company_records = [\n",
    "    (row[\"company_id\"], row[\"corp_number\"], row[\"edinet_code\"], row[\"security_code\"])\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO companies (company_id, corp_number, edinet_code, security_code)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (company_id) DO UPDATE\n",
    "    SET corp_number = EXCLUDED.corp_number,\n",
    "        edinet_code = EXCLUDED.edinet_code,\n",
    "        security_code = EXCLUDED.security_code;\n",
    "\"\"\",\n",
    "    company_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¥ company_profiles ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥ or æ›´æ–° ----------\n",
    "profile_records = [\n",
    "    (\n",
    "        row[\"company_id\"],\n",
    "        YEAR,\n",
    "        row[\"name_ja\"],\n",
    "        row[\"name_en\"],\n",
    "        row[\"sector_17\"],\n",
    "        row[\"sector_33\"],\n",
    "        row[\"scale_category\"],\n",
    "        row[\"market_code\"].zfill(3),\n",
    "        row[\"address\"],\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO company_profiles (\n",
    "        company_id, year, name_ja, name_en,\n",
    "        sector_17, sector_33, scale_category, market_code, address\n",
    "    ) VALUES %s\n",
    "    ON CONFLICT (company_id, year) DO UPDATE\n",
    "    SET name_ja = EXCLUDED.name_ja,\n",
    "        name_en = EXCLUDED.name_en,\n",
    "        sector_17 = EXCLUDED.sector_17,\n",
    "        sector_33 = EXCLUDED.sector_33,\n",
    "        scale_category = EXCLUDED.scale_category,\n",
    "        market_code = EXCLUDED.market_code,\n",
    "        address = EXCLUDED.address;\n",
    "\"\"\",\n",
    "    profile_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¦ ã‚³ãƒŸãƒƒãƒˆ & çµ‚äº†å‡¦ç† ----------\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"âœ… {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {YEAR} å¹´åˆ†ã¨ã—ã¦æŒ¿å…¥ãƒ»æ›´æ–°ã—ã¾ã—ãŸã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2021\n",
    "from scripts.preprocess import load_topix_and_edinet\n",
    "\n",
    "df_2021 = load_topix_and_edinet(\n",
    "    \"data/raw/topix_growth_snapshots/2021_topix_growth.csv\",\n",
    "    \"data/raw/EdinetcodeDlInfo.csv\",\n",
    ")\n",
    "df_2021.to_csv(\"data/processed/topix_companies_2021.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67430a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰‹å‹•å‡¦ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75dc125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "from psycopg2.extras import execute_values\n",
    "from db.connection import get_connection\n",
    "from scripts.preprocess import overwrite_company_ids_if_exists\n",
    "\n",
    "# ----------- â‘  å¹´åº¦æŒ‡å®š & ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ ----------\n",
    "YEAR = 2021\n",
    "CSV_PATH = f\"data/processed/topix_companies_{YEAR}.csv\"\n",
    "\n",
    "# ----------- â‘¡ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & ã‚«ãƒ©ãƒ çµ±ä¸€ ----------\n",
    "df = pd.read_csv(CSV_PATH, dtype=str).fillna(\"\")\n",
    "\n",
    "column_map = {\n",
    "    \"æå‡ºè€…å\": \"name_ja\",\n",
    "    \"æå‡ºè€…æ³•äººç•ªå·\": \"corp_number\",\n",
    "    \"ï¼¥ï¼¤ï¼©ï¼®ï¼¥ï¼´ã‚³ãƒ¼ãƒ‰\": \"edinet_code\",\n",
    "    \"Code\": \"security_code\",\n",
    "    \"æå‡ºè€…æ¥­ç¨®\": \"sector_33\",\n",
    "    \"Sector17CodeName\": \"sector_17\",\n",
    "    \"ScaleCategory\": \"scale_category\",\n",
    "    \"MarketCode\": \"market_code\",\n",
    "    \"æå‡ºè€…åï¼ˆè‹±å­—ï¼‰\": \"name_en\",\n",
    "    \"æ‰€åœ¨åœ°\": \"address\",\n",
    "}\n",
    "df = df.rename(columns=column_map)\n",
    "\n",
    "keep_cols = [\n",
    "    \"security_code\",\n",
    "    \"name_ja\",\n",
    "    \"name_en\",\n",
    "    \"sector_17\",\n",
    "    \"sector_33\",\n",
    "    \"scale_category\",\n",
    "    \"market_code\",\n",
    "    \"edinet_code\",\n",
    "    \"address\",\n",
    "    \"corp_number\",\n",
    "]\n",
    "df = df[keep_cols]\n",
    "\n",
    "# æ•´å½¢å‡¦ç†\n",
    "df[\"security_code\"] = df[\"security_code\"].str.zfill(5)\n",
    "df[\"edinet_code\"] = df[\"edinet_code\"].str.zfill(6)\n",
    "df[\"corp_number\"] = df[\"corp_number\"].apply(\n",
    "    lambda x: str(int(float(x))).zfill(13) if pd.notnull(x) and x != \"\" else \"\"\n",
    ")\n",
    "\n",
    "# ----------- â‘¢ DBæ¥ç¶š & company_id ä¸Šæ›¸ã ----------\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "df = overwrite_company_ids_if_exists(df, cur)\n",
    "\n",
    "\n",
    "# ----------- â‘£ UUIDãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ & é‡è¤‡ãƒã‚§ãƒƒã‚¯ ----------\n",
    "def is_valid_uuid(val: str) -> bool:\n",
    "    try:\n",
    "        uuid.UUID(str(val))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "df[\"company_id\"] = df[\"company_id\"].astype(str)\n",
    "valid_mask = df[\"company_id\"].apply(is_valid_uuid)\n",
    "\n",
    "# ç„¡åŠ¹ãªUUIDæ¤œå‡º\n",
    "invalid_df = df[~valid_mask]\n",
    "if not invalid_df.empty:\n",
    "    print(\"ğŸŸ¥ ç„¡åŠ¹ãª company_id ã‚’æŒã¤ãƒ¬ã‚³ãƒ¼ãƒ‰:\")\n",
    "    display(invalid_df)\n",
    "\n",
    "# é‡è¤‡æ¤œå‡º\n",
    "duplicates = df[valid_mask].duplicated(subset=[\"company_id\"], keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"âš ï¸ company_id ãŒé‡è¤‡ã—ã¦ã„ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆåŒä¸€å¹´åº¦å†…ï¼‰:\")\n",
    "    display(df[valid_mask][duplicates])\n",
    "\n",
    "# æœ‰åŠ¹ãªUUIDã®ã¿æ®‹ã™\n",
    "df = df[valid_mask].copy()\n",
    "\n",
    "print(\"ğŸ” company_idãŒæœ‰åŠ¹ãªä»¶æ•°:\", len(df))\n",
    "print(\"âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯ãª company_id ä»¶æ•°:\", df[\"company_id\"].nunique())\n",
    "\n",
    "# ----------- â‘¤ companies ãƒ†ãƒ¼ãƒ–ãƒ«ã«å…ˆã«æŒ¿å…¥ï¼ˆå¤–éƒ¨ã‚­ãƒ¼ç”¨ï¼‰ ----------\n",
    "company_records = [\n",
    "    (row[\"company_id\"], row[\"corp_number\"], row[\"edinet_code\"], row[\"security_code\"])\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO companies (company_id, corp_number, edinet_code, security_code)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (company_id) DO UPDATE\n",
    "    SET corp_number = EXCLUDED.corp_number,\n",
    "        edinet_code = EXCLUDED.edinet_code,\n",
    "        security_code = EXCLUDED.security_code;\n",
    "\"\"\",\n",
    "    company_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¥ company_profiles ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥ or æ›´æ–° ----------\n",
    "profile_records = [\n",
    "    (\n",
    "        row[\"company_id\"],\n",
    "        YEAR,\n",
    "        row[\"name_ja\"],\n",
    "        row[\"name_en\"],\n",
    "        row[\"sector_17\"],\n",
    "        row[\"sector_33\"],\n",
    "        row[\"scale_category\"],\n",
    "        row[\"market_code\"].zfill(3),\n",
    "        row[\"address\"],\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO company_profiles (\n",
    "        company_id, year, name_ja, name_en,\n",
    "        sector_17, sector_33, scale_category, market_code, address\n",
    "    ) VALUES %s\n",
    "    ON CONFLICT (company_id, year) DO UPDATE\n",
    "    SET name_ja = EXCLUDED.name_ja,\n",
    "        name_en = EXCLUDED.name_en,\n",
    "        sector_17 = EXCLUDED.sector_17,\n",
    "        sector_33 = EXCLUDED.sector_33,\n",
    "        scale_category = EXCLUDED.scale_category,\n",
    "        market_code = EXCLUDED.market_code,\n",
    "        address = EXCLUDED.address;\n",
    "\"\"\",\n",
    "    profile_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¦ ã‚³ãƒŸãƒƒãƒˆ & çµ‚äº†å‡¦ç† ----------\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"âœ… {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {YEAR} å¹´åˆ†ã¨ã—ã¦æŒ¿å…¥ãƒ»æ›´æ–°ã—ã¾ã—ãŸã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb99ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2022\n",
    "from scripts.preprocess import load_topix_and_edinet\n",
    "\n",
    "df_2022 = load_topix_and_edinet(\n",
    "    \"data/raw/topix_growth_snapshots/2022_topix_growth.csv\",\n",
    "    \"data/raw/EdinetcodeDlInfo.csv\",\n",
    ")\n",
    "df_2022.to_csv(\"data/processed/topix_companies_2022.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edcaa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## æ‰‹å‹•å‡¦ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4655dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "from psycopg2.extras import execute_values\n",
    "from db.connection import get_connection\n",
    "from scripts.preprocess import overwrite_company_ids_if_exists\n",
    "\n",
    "# ----------- â‘  å¹´åº¦æŒ‡å®š & ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ ----------\n",
    "YEAR = 2022\n",
    "CSV_PATH = f\"data/processed/topix_companies_{YEAR}.csv\"\n",
    "\n",
    "# ----------- â‘¡ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & ã‚«ãƒ©ãƒ çµ±ä¸€ ----------\n",
    "df = pd.read_csv(CSV_PATH, dtype=str).fillna(\"\")\n",
    "\n",
    "column_map = {\n",
    "    \"æå‡ºè€…å\": \"name_ja\",\n",
    "    \"æå‡ºè€…æ³•äººç•ªå·\": \"corp_number\",\n",
    "    \"ï¼¥ï¼¤ï¼©ï¼®ï¼¥ï¼´ã‚³ãƒ¼ãƒ‰\": \"edinet_code\",\n",
    "    \"Code\": \"security_code\",\n",
    "    \"æå‡ºè€…æ¥­ç¨®\": \"sector_33\",\n",
    "    \"Sector17CodeName\": \"sector_17\",\n",
    "    \"ScaleCategory\": \"scale_category\",\n",
    "    \"MarketCode\": \"market_code\",\n",
    "    \"æå‡ºè€…åï¼ˆè‹±å­—ï¼‰\": \"name_en\",\n",
    "    \"æ‰€åœ¨åœ°\": \"address\",\n",
    "}\n",
    "df = df.rename(columns=column_map)\n",
    "\n",
    "keep_cols = [\n",
    "    \"security_code\",\n",
    "    \"name_ja\",\n",
    "    \"name_en\",\n",
    "    \"sector_17\",\n",
    "    \"sector_33\",\n",
    "    \"scale_category\",\n",
    "    \"market_code\",\n",
    "    \"edinet_code\",\n",
    "    \"address\",\n",
    "    \"corp_number\",\n",
    "]\n",
    "df = df[keep_cols]\n",
    "\n",
    "# æ•´å½¢å‡¦ç†\n",
    "df[\"security_code\"] = df[\"security_code\"].str.zfill(5)\n",
    "df[\"edinet_code\"] = df[\"edinet_code\"].str.zfill(6)\n",
    "df[\"corp_number\"] = df[\"corp_number\"].apply(\n",
    "    lambda x: str(int(float(x))).zfill(13) if pd.notnull(x) and x != \"\" else \"\"\n",
    ")\n",
    "\n",
    "# ----------- â‘¢ DBæ¥ç¶š & company_id ä¸Šæ›¸ã ----------\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "df = overwrite_company_ids_if_exists(df, cur)\n",
    "\n",
    "\n",
    "# ----------- â‘£ UUIDãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ & é‡è¤‡ãƒã‚§ãƒƒã‚¯ ----------\n",
    "def is_valid_uuid(val: str) -> bool:\n",
    "    try:\n",
    "        uuid.UUID(str(val))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "df[\"company_id\"] = df[\"company_id\"].astype(str)\n",
    "valid_mask = df[\"company_id\"].apply(is_valid_uuid)\n",
    "\n",
    "# ç„¡åŠ¹ãªUUIDæ¤œå‡º\n",
    "invalid_df = df[~valid_mask]\n",
    "if not invalid_df.empty:\n",
    "    print(\"ğŸŸ¥ ç„¡åŠ¹ãª company_id ã‚’æŒã¤ãƒ¬ã‚³ãƒ¼ãƒ‰:\")\n",
    "    display(invalid_df)\n",
    "\n",
    "# é‡è¤‡æ¤œå‡º\n",
    "duplicates = df[valid_mask].duplicated(subset=[\"company_id\"], keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"âš ï¸ company_id ãŒé‡è¤‡ã—ã¦ã„ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆåŒä¸€å¹´åº¦å†…ï¼‰:\")\n",
    "    display(df[valid_mask][duplicates])\n",
    "\n",
    "# æœ‰åŠ¹ãªUUIDã®ã¿æ®‹ã™\n",
    "df = df[valid_mask].copy()\n",
    "\n",
    "print(\"ğŸ” company_idãŒæœ‰åŠ¹ãªä»¶æ•°:\", len(df))\n",
    "print(\"âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯ãª company_id ä»¶æ•°:\", df[\"company_id\"].nunique())\n",
    "\n",
    "# ----------- â‘¤ companies ãƒ†ãƒ¼ãƒ–ãƒ«ã«å…ˆã«æŒ¿å…¥ï¼ˆå¤–éƒ¨ã‚­ãƒ¼ç”¨ï¼‰ ----------\n",
    "company_records = [\n",
    "    (row[\"company_id\"], row[\"corp_number\"], row[\"edinet_code\"], row[\"security_code\"])\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO companies (company_id, corp_number, edinet_code, security_code)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (company_id) DO UPDATE\n",
    "    SET corp_number = EXCLUDED.corp_number,\n",
    "        edinet_code = EXCLUDED.edinet_code,\n",
    "        security_code = EXCLUDED.security_code;\n",
    "\"\"\",\n",
    "    company_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¥ company_profiles ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥ or æ›´æ–° ----------\n",
    "profile_records = [\n",
    "    (\n",
    "        row[\"company_id\"],\n",
    "        YEAR,\n",
    "        row[\"name_ja\"],\n",
    "        row[\"name_en\"],\n",
    "        row[\"sector_17\"],\n",
    "        row[\"sector_33\"],\n",
    "        row[\"scale_category\"],\n",
    "        row[\"market_code\"].zfill(3),\n",
    "        row[\"address\"],\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO company_profiles (\n",
    "        company_id, year, name_ja, name_en,\n",
    "        sector_17, sector_33, scale_category, market_code, address\n",
    "    ) VALUES %s\n",
    "    ON CONFLICT (company_id, year) DO UPDATE\n",
    "    SET name_ja = EXCLUDED.name_ja,\n",
    "        name_en = EXCLUDED.name_en,\n",
    "        sector_17 = EXCLUDED.sector_17,\n",
    "        sector_33 = EXCLUDED.sector_33,\n",
    "        scale_category = EXCLUDED.scale_category,\n",
    "        market_code = EXCLUDED.market_code,\n",
    "        address = EXCLUDED.address;\n",
    "\"\"\",\n",
    "    profile_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¦ ã‚³ãƒŸãƒƒãƒˆ & çµ‚äº†å‡¦ç† ----------\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"âœ… {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {YEAR} å¹´åˆ†ã¨ã—ã¦æŒ¿å…¥ãƒ»æ›´æ–°ã—ã¾ã—ãŸã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac56fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023\n",
    "from scripts.preprocess import load_topix_and_edinet\n",
    "\n",
    "df_2023 = load_topix_and_edinet(\n",
    "    \"data/raw/topix_growth_snapshots/2023_topix_growth.csv\",\n",
    "    \"data/raw/EdinetcodeDlInfo.csv\",\n",
    ")\n",
    "df_2023.to_csv(\"data/processed/topix_companies_2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd9f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## æ‰‹å‹•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3565bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "from psycopg2.extras import execute_values\n",
    "from db.connection import get_connection\n",
    "from scripts.preprocess import overwrite_company_ids_if_exists\n",
    "\n",
    "# ----------- â‘  å¹´åº¦æŒ‡å®š & ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ ----------\n",
    "YEAR = 2023\n",
    "CSV_PATH = f\"data/processed/topix_companies_{YEAR}.csv\"\n",
    "\n",
    "# ----------- â‘¡ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & ã‚«ãƒ©ãƒ çµ±ä¸€ ----------\n",
    "df = pd.read_csv(CSV_PATH, dtype=str).fillna(\"\")\n",
    "\n",
    "column_map = {\n",
    "    \"æå‡ºè€…å\": \"name_ja\",\n",
    "    \"æå‡ºè€…æ³•äººç•ªå·\": \"corp_number\",\n",
    "    \"ï¼¥ï¼¤ï¼©ï¼®ï¼¥ï¼´ã‚³ãƒ¼ãƒ‰\": \"edinet_code\",\n",
    "    \"Code\": \"security_code\",\n",
    "    \"æå‡ºè€…æ¥­ç¨®\": \"sector_33\",\n",
    "    \"Sector17CodeName\": \"sector_17\",\n",
    "    \"ScaleCategory\": \"scale_category\",\n",
    "    \"MarketCode\": \"market_code\",\n",
    "    \"æå‡ºè€…åï¼ˆè‹±å­—ï¼‰\": \"name_en\",\n",
    "    \"æ‰€åœ¨åœ°\": \"address\",\n",
    "}\n",
    "df = df.rename(columns=column_map)\n",
    "\n",
    "keep_cols = [\n",
    "    \"security_code\",\n",
    "    \"name_ja\",\n",
    "    \"name_en\",\n",
    "    \"sector_17\",\n",
    "    \"sector_33\",\n",
    "    \"scale_category\",\n",
    "    \"market_code\",\n",
    "    \"edinet_code\",\n",
    "    \"address\",\n",
    "    \"corp_number\",\n",
    "]\n",
    "df = df[keep_cols]\n",
    "\n",
    "# æ•´å½¢å‡¦ç†\n",
    "df[\"security_code\"] = df[\"security_code\"].str.zfill(5)\n",
    "df[\"edinet_code\"] = df[\"edinet_code\"].str.zfill(6)\n",
    "df[\"corp_number\"] = df[\"corp_number\"].apply(\n",
    "    lambda x: str(int(float(x))).zfill(13) if pd.notnull(x) and x != \"\" else \"\"\n",
    ")\n",
    "\n",
    "# ----------- â‘¢ DBæ¥ç¶š & company_id ä¸Šæ›¸ã ----------\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "df = overwrite_company_ids_if_exists(df, cur)\n",
    "\n",
    "\n",
    "# ----------- â‘£ UUIDãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ & é‡è¤‡ãƒã‚§ãƒƒã‚¯ ----------\n",
    "def is_valid_uuid(val: str) -> bool:\n",
    "    try:\n",
    "        uuid.UUID(str(val))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "df[\"company_id\"] = df[\"company_id\"].astype(str)\n",
    "valid_mask = df[\"company_id\"].apply(is_valid_uuid)\n",
    "\n",
    "# ç„¡åŠ¹ãªUUIDæ¤œå‡º\n",
    "invalid_df = df[~valid_mask]\n",
    "if not invalid_df.empty:\n",
    "    print(\"ğŸŸ¥ ç„¡åŠ¹ãª company_id ã‚’æŒã¤ãƒ¬ã‚³ãƒ¼ãƒ‰:\")\n",
    "    display(invalid_df)\n",
    "\n",
    "# é‡è¤‡æ¤œå‡º\n",
    "duplicates = df[valid_mask].duplicated(subset=[\"company_id\"], keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"âš ï¸ company_id ãŒé‡è¤‡ã—ã¦ã„ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆåŒä¸€å¹´åº¦å†…ï¼‰:\")\n",
    "    display(df[valid_mask][duplicates])\n",
    "\n",
    "# æœ‰åŠ¹ãªUUIDã®ã¿æ®‹ã™\n",
    "df = df[valid_mask].copy()\n",
    "\n",
    "print(\"ğŸ” company_idãŒæœ‰åŠ¹ãªä»¶æ•°:\", len(df))\n",
    "print(\"âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯ãª company_id ä»¶æ•°:\", df[\"company_id\"].nunique())\n",
    "\n",
    "# ----------- â‘¤ companies ãƒ†ãƒ¼ãƒ–ãƒ«ã«å…ˆã«æŒ¿å…¥ï¼ˆå¤–éƒ¨ã‚­ãƒ¼ç”¨ï¼‰ ----------\n",
    "company_records = [\n",
    "    (row[\"company_id\"], row[\"corp_number\"], row[\"edinet_code\"], row[\"security_code\"])\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO companies (company_id, corp_number, edinet_code, security_code)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (company_id) DO UPDATE\n",
    "    SET corp_number = EXCLUDED.corp_number,\n",
    "        edinet_code = EXCLUDED.edinet_code,\n",
    "        security_code = EXCLUDED.security_code;\n",
    "\"\"\",\n",
    "    company_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¥ company_profiles ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥ or æ›´æ–° ----------\n",
    "profile_records = [\n",
    "    (\n",
    "        row[\"company_id\"],\n",
    "        YEAR,\n",
    "        row[\"name_ja\"],\n",
    "        row[\"name_en\"],\n",
    "        row[\"sector_17\"],\n",
    "        row[\"sector_33\"],\n",
    "        row[\"scale_category\"],\n",
    "        row[\"market_code\"].zfill(3),\n",
    "        row[\"address\"],\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO company_profiles (\n",
    "        company_id, year, name_ja, name_en,\n",
    "        sector_17, sector_33, scale_category, market_code, address\n",
    "    ) VALUES %s\n",
    "    ON CONFLICT (company_id, year) DO UPDATE\n",
    "    SET name_ja = EXCLUDED.name_ja,\n",
    "        name_en = EXCLUDED.name_en,\n",
    "        sector_17 = EXCLUDED.sector_17,\n",
    "        sector_33 = EXCLUDED.sector_33,\n",
    "        scale_category = EXCLUDED.scale_category,\n",
    "        market_code = EXCLUDED.market_code,\n",
    "        address = EXCLUDED.address;\n",
    "\"\"\",\n",
    "    profile_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¦ ã‚³ãƒŸãƒƒãƒˆ & çµ‚äº†å‡¦ç† ----------\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"âœ… {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {YEAR} å¹´åˆ†ã¨ã—ã¦æŒ¿å…¥ãƒ»æ›´æ–°ã—ã¾ã—ãŸã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405a80d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2024\n",
    "from scripts.preprocess import load_topix_and_edinet\n",
    "\n",
    "df_2024 = load_topix_and_edinet(\n",
    "    \"data/raw/topix_growth_snapshots/2024_topix_growth.csv\",\n",
    "    \"data/raw/EdinetcodeDlInfo.csv\",\n",
    ")\n",
    "df_2024.to_csv(\"data/processed/topix_companies_2024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09703d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## æ‰‹å‹•ã§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03327929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "from psycopg2.extras import execute_values\n",
    "from db.connection import get_connection\n",
    "from scripts.preprocess import overwrite_company_ids_if_exists\n",
    "\n",
    "# ----------- â‘  å¹´åº¦æŒ‡å®š & ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ ----------\n",
    "YEAR = 2024\n",
    "CSV_PATH = f\"data/processed/topix_companies_{YEAR}.csv\"\n",
    "\n",
    "# ----------- â‘¡ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & ã‚«ãƒ©ãƒ çµ±ä¸€ ----------\n",
    "df = pd.read_csv(CSV_PATH, dtype=str).fillna(\"\")\n",
    "\n",
    "column_map = {\n",
    "    \"æå‡ºè€…å\": \"name_ja\",\n",
    "    \"æå‡ºè€…æ³•äººç•ªå·\": \"corp_number\",\n",
    "    \"ï¼¥ï¼¤ï¼©ï¼®ï¼¥ï¼´ã‚³ãƒ¼ãƒ‰\": \"edinet_code\",\n",
    "    \"Code\": \"security_code\",\n",
    "    \"æå‡ºè€…æ¥­ç¨®\": \"sector_33\",\n",
    "    \"Sector17CodeName\": \"sector_17\",\n",
    "    \"ScaleCategory\": \"scale_category\",\n",
    "    \"MarketCode\": \"market_code\",\n",
    "    \"æå‡ºè€…åï¼ˆè‹±å­—ï¼‰\": \"name_en\",\n",
    "    \"æ‰€åœ¨åœ°\": \"address\",\n",
    "}\n",
    "df = df.rename(columns=column_map)\n",
    "\n",
    "keep_cols = [\n",
    "    \"security_code\",\n",
    "    \"name_ja\",\n",
    "    \"name_en\",\n",
    "    \"sector_17\",\n",
    "    \"sector_33\",\n",
    "    \"scale_category\",\n",
    "    \"market_code\",\n",
    "    \"edinet_code\",\n",
    "    \"address\",\n",
    "    \"corp_number\",\n",
    "]\n",
    "df = df[keep_cols]\n",
    "\n",
    "# æ•´å½¢å‡¦ç†\n",
    "df[\"security_code\"] = df[\"security_code\"].str.zfill(5)\n",
    "df[\"edinet_code\"] = df[\"edinet_code\"].str.zfill(6)\n",
    "df[\"corp_number\"] = df[\"corp_number\"].apply(\n",
    "    lambda x: str(int(float(x))).zfill(13) if pd.notnull(x) and x != \"\" else \"\"\n",
    ")\n",
    "\n",
    "# ----------- â‘¢ DBæ¥ç¶š & company_id ä¸Šæ›¸ã ----------\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "df = overwrite_company_ids_if_exists(df, cur)\n",
    "\n",
    "\n",
    "# ----------- â‘£ UUIDãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ & é‡è¤‡ãƒã‚§ãƒƒã‚¯ ----------\n",
    "def is_valid_uuid(val: str) -> bool:\n",
    "    try:\n",
    "        uuid.UUID(str(val))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "df[\"company_id\"] = df[\"company_id\"].astype(str)\n",
    "valid_mask = df[\"company_id\"].apply(is_valid_uuid)\n",
    "\n",
    "# ç„¡åŠ¹ãªUUIDæ¤œå‡º\n",
    "invalid_df = df[~valid_mask]\n",
    "if not invalid_df.empty:\n",
    "    print(\"ğŸŸ¥ ç„¡åŠ¹ãª company_id ã‚’æŒã¤ãƒ¬ã‚³ãƒ¼ãƒ‰:\")\n",
    "    display(invalid_df)\n",
    "\n",
    "# é‡è¤‡æ¤œå‡º\n",
    "duplicates = df[valid_mask].duplicated(subset=[\"company_id\"], keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"âš ï¸ company_id ãŒé‡è¤‡ã—ã¦ã„ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆåŒä¸€å¹´åº¦å†…ï¼‰:\")\n",
    "    display(df[valid_mask][duplicates])\n",
    "\n",
    "# æœ‰åŠ¹ãªUUIDã®ã¿æ®‹ã™\n",
    "df = df[valid_mask].copy()\n",
    "\n",
    "print(\"ğŸ” company_idãŒæœ‰åŠ¹ãªä»¶æ•°:\", len(df))\n",
    "print(\"âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯ãª company_id ä»¶æ•°:\", df[\"company_id\"].nunique())\n",
    "\n",
    "# ----------- â‘¤ companies ãƒ†ãƒ¼ãƒ–ãƒ«ã«å…ˆã«æŒ¿å…¥ï¼ˆå¤–éƒ¨ã‚­ãƒ¼ç”¨ï¼‰ ----------\n",
    "company_records = [\n",
    "    (row[\"company_id\"], row[\"corp_number\"], row[\"edinet_code\"], row[\"security_code\"])\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO companies (company_id, corp_number, edinet_code, security_code)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (company_id) DO UPDATE\n",
    "    SET corp_number = EXCLUDED.corp_number,\n",
    "        edinet_code = EXCLUDED.edinet_code,\n",
    "        security_code = EXCLUDED.security_code;\n",
    "\"\"\",\n",
    "    company_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¥ company_profiles ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥ or æ›´æ–° ----------\n",
    "profile_records = [\n",
    "    (\n",
    "        row[\"company_id\"],\n",
    "        YEAR,\n",
    "        row[\"name_ja\"],\n",
    "        row[\"name_en\"],\n",
    "        row[\"sector_17\"],\n",
    "        row[\"sector_33\"],\n",
    "        row[\"scale_category\"],\n",
    "        row[\"market_code\"].zfill(3),\n",
    "        row[\"address\"],\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO company_profiles (\n",
    "        company_id, year, name_ja, name_en,\n",
    "        sector_17, sector_33, scale_category, market_code, address\n",
    "    ) VALUES %s\n",
    "    ON CONFLICT (company_id, year) DO UPDATE\n",
    "    SET name_ja = EXCLUDED.name_ja,\n",
    "        name_en = EXCLUDED.name_en,\n",
    "        sector_17 = EXCLUDED.sector_17,\n",
    "        sector_33 = EXCLUDED.sector_33,\n",
    "        scale_category = EXCLUDED.scale_category,\n",
    "        market_code = EXCLUDED.market_code,\n",
    "        address = EXCLUDED.address;\n",
    "\"\"\",\n",
    "    profile_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¦ ã‚³ãƒŸãƒƒãƒˆ & çµ‚äº†å‡¦ç† ----------\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"âœ… {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {YEAR} å¹´åˆ†ã¨ã—ã¦æŒ¿å…¥ãƒ»æ›´æ–°ã—ã¾ã—ãŸã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2025\n",
    "from scripts.preprocess import load_topix_and_edinet\n",
    "\n",
    "df_2025 = load_topix_and_edinet(\n",
    "    \"data/raw/topix_growth_snapshots/2025_topix_growth.csv\",\n",
    "    \"data/raw/EdinetcodeDlInfo.csv\",\n",
    ")\n",
    "df_2025.to_csv(\"data/processed/topix_companies_2025.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## æ‰‹å‹•ãƒã‚§ãƒƒã‚¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "from psycopg2.extras import execute_values\n",
    "from db.connection import get_connection\n",
    "from scripts.preprocess import overwrite_company_ids_if_exists\n",
    "\n",
    "# ----------- â‘  å¹´åº¦æŒ‡å®š & ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ ----------\n",
    "YEAR = 2025\n",
    "CSV_PATH = f\"data/processed/topix_companies_{YEAR}.csv\"\n",
    "\n",
    "# ----------- â‘¡ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & ã‚«ãƒ©ãƒ çµ±ä¸€ ----------\n",
    "df = pd.read_csv(CSV_PATH, dtype=str).fillna(\"\")\n",
    "\n",
    "column_map = {\n",
    "    \"æå‡ºè€…å\": \"name_ja\",\n",
    "    \"æå‡ºè€…æ³•äººç•ªå·\": \"corp_number\",\n",
    "    \"ï¼¥ï¼¤ï¼©ï¼®ï¼¥ï¼´ã‚³ãƒ¼ãƒ‰\": \"edinet_code\",\n",
    "    \"Code\": \"security_code\",\n",
    "    \"æå‡ºè€…æ¥­ç¨®\": \"sector_33\",\n",
    "    \"Sector17CodeName\": \"sector_17\",\n",
    "    \"ScaleCategory\": \"scale_category\",\n",
    "    \"MarketCode\": \"market_code\",\n",
    "    \"æå‡ºè€…åï¼ˆè‹±å­—ï¼‰\": \"name_en\",\n",
    "    \"æ‰€åœ¨åœ°\": \"address\",\n",
    "}\n",
    "df = df.rename(columns=column_map)\n",
    "\n",
    "keep_cols = [\n",
    "    \"security_code\",\n",
    "    \"name_ja\",\n",
    "    \"name_en\",\n",
    "    \"sector_17\",\n",
    "    \"sector_33\",\n",
    "    \"scale_category\",\n",
    "    \"market_code\",\n",
    "    \"edinet_code\",\n",
    "    \"address\",\n",
    "    \"corp_number\",\n",
    "]\n",
    "df = df[keep_cols]\n",
    "\n",
    "# æ•´å½¢å‡¦ç†\n",
    "df[\"security_code\"] = df[\"security_code\"].str.zfill(5)\n",
    "df[\"edinet_code\"] = df[\"edinet_code\"].str.zfill(6)\n",
    "df[\"corp_number\"] = df[\"corp_number\"].apply(\n",
    "    lambda x: str(int(float(x))).zfill(13) if pd.notnull(x) and x != \"\" else \"\"\n",
    ")\n",
    "\n",
    "# ----------- â‘¢ DBæ¥ç¶š & company_id ä¸Šæ›¸ã ----------\n",
    "conn = get_connection()\n",
    "cur = conn.cursor()\n",
    "df = overwrite_company_ids_if_exists(df, cur)\n",
    "\n",
    "\n",
    "# ----------- â‘£ UUIDãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ & é‡è¤‡ãƒã‚§ãƒƒã‚¯ ----------\n",
    "def is_valid_uuid(val: str) -> bool:\n",
    "    try:\n",
    "        uuid.UUID(str(val))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "df[\"company_id\"] = df[\"company_id\"].astype(str)\n",
    "valid_mask = df[\"company_id\"].apply(is_valid_uuid)\n",
    "\n",
    "# ç„¡åŠ¹ãªUUIDæ¤œå‡º\n",
    "invalid_df = df[~valid_mask]\n",
    "if not invalid_df.empty:\n",
    "    print(\"ğŸŸ¥ ç„¡åŠ¹ãª company_id ã‚’æŒã¤ãƒ¬ã‚³ãƒ¼ãƒ‰:\")\n",
    "    display(invalid_df)\n",
    "\n",
    "# é‡è¤‡æ¤œå‡º\n",
    "duplicates = df[valid_mask].duplicated(subset=[\"company_id\"], keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"âš ï¸ company_id ãŒé‡è¤‡ã—ã¦ã„ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼ˆåŒä¸€å¹´åº¦å†…ï¼‰:\")\n",
    "    display(df[valid_mask][duplicates])\n",
    "\n",
    "# æœ‰åŠ¹ãªUUIDã®ã¿æ®‹ã™\n",
    "df = df[valid_mask].copy()\n",
    "\n",
    "print(\"ğŸ” company_idãŒæœ‰åŠ¹ãªä»¶æ•°:\", len(df))\n",
    "print(\"âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯ãª company_id ä»¶æ•°:\", df[\"company_id\"].nunique())\n",
    "\n",
    "# ----------- â‘¤ companies ãƒ†ãƒ¼ãƒ–ãƒ«ã«å…ˆã«æŒ¿å…¥ï¼ˆå¤–éƒ¨ã‚­ãƒ¼ç”¨ï¼‰ ----------\n",
    "company_records = [\n",
    "    (row[\"company_id\"], row[\"corp_number\"], row[\"edinet_code\"], row[\"security_code\"])\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO companies (company_id, corp_number, edinet_code, security_code)\n",
    "    VALUES %s\n",
    "    ON CONFLICT (company_id) DO UPDATE\n",
    "    SET corp_number = EXCLUDED.corp_number,\n",
    "        edinet_code = EXCLUDED.edinet_code,\n",
    "        security_code = EXCLUDED.security_code;\n",
    "\"\"\",\n",
    "    company_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¥ company_profiles ãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥ or æ›´æ–° ----------\n",
    "profile_records = [\n",
    "    (\n",
    "        row[\"company_id\"],\n",
    "        YEAR,\n",
    "        row[\"name_ja\"],\n",
    "        row[\"name_en\"],\n",
    "        row[\"sector_17\"],\n",
    "        row[\"sector_33\"],\n",
    "        row[\"scale_category\"],\n",
    "        row[\"market_code\"].zfill(3),\n",
    "        row[\"address\"],\n",
    "    )\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"\"\"\n",
    "    INSERT INTO company_profiles (\n",
    "        company_id, year, name_ja, name_en,\n",
    "        sector_17, sector_33, scale_category, market_code, address\n",
    "    ) VALUES %s\n",
    "    ON CONFLICT (company_id, year) DO UPDATE\n",
    "    SET name_ja = EXCLUDED.name_ja,\n",
    "        name_en = EXCLUDED.name_en,\n",
    "        sector_17 = EXCLUDED.sector_17,\n",
    "        sector_33 = EXCLUDED.sector_33,\n",
    "        scale_category = EXCLUDED.scale_category,\n",
    "        market_code = EXCLUDED.market_code,\n",
    "        address = EXCLUDED.address;\n",
    "\"\"\",\n",
    "    profile_records,\n",
    ")\n",
    "\n",
    "# ----------- â‘¦ ã‚³ãƒŸãƒƒãƒˆ & çµ‚äº†å‡¦ç† ----------\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"âœ… {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {YEAR} å¹´åˆ†ã¨ã—ã¦æŒ¿å…¥ãƒ»æ›´æ–°ã—ã¾ã—ãŸã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cfaf28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sotsuken (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
